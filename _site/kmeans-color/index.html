<!DOCTYPE html><html lang="en-US"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"> <!-- Begin Jekyll SEO tag v2.6.1 --><title>K-Means Clustering for Image Color Segmentation | Christopher’s Blog</title><meta name="generator" content="Jekyll v3.9.0" /><meta property="og:title" content="K-Means Clustering for Image Color Segmentation" /><meta name="author" content="Christopher Ton" /><meta property="og:locale" content="en_US" /><meta name="description" content="Extracting Information from Images Using K-Means Clustering" /><meta property="og:description" content="Extracting Information from Images Using K-Means Clustering" /><link rel="canonical" href="http://localhost:4000/kmeans-color/" /><meta property="og:url" content="http://localhost:4000/kmeans-color/" /><meta property="og:site_name" content="Christopher’s Blog" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2020-01-02T00:00:00-08:00" /> <script type="application/ld+json"> {"@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/kmeans-color/"},"url":"http://localhost:4000/kmeans-color/","author":{"@type":"Person","name":"Christopher Ton"},"description":"Extracting Information from Images Using K-Means Clustering","headline":"K-Means Clustering for Image Color Segmentation","dateModified":"2020-01-02T00:00:00-08:00","datePublished":"2020-01-02T00:00:00-08:00","@context":"https://schema.org"}</script> <!-- End Jekyll SEO tag --><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/icons/apple-touch-icon.png?v=qA3OXqyw77"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/icons/favicon-32x32.png?v=qA3OXqyw77"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/icons/favicon-16x16.png?v=qA3OXqyw77"><link rel="manifest" href="/assets/img/icons/manifest.json?v=qA3OXqyw77"><link rel="mask-icon" href="/assets/img/icons/safari-pinned-tab.svg?v=qA3OXqyw77" color="#5bbad5"> <!--[if IE]><link rel="shortcut icon" href="/assets/img/icons/favicon.ico?v=qA3OXqyw77"><![endif]--><link rel="shortcut icon" href="/assets/img/icons/favicon.ico?v=qA3OXqyw77"><meta name="apple-mobile-web-app-title" content="Sleek"><meta name="application-name" content="Sleek"><meta name="msapplication-config" content="/assets/img/icons/browserconfig.xml?v=qA3OXqyw77"><meta name="theme-color" content="#ffffff"><style class="inlineCSS"> h1{color:#313237;margin-top:0;margin-bottom:.5rem}.dark-bg{background-color:#313237}@media only screen and (min-width:48em){.post-card{width:48.4375%;margin-right:3.125%}.post-card:last-of-type,.post-card:nth-child(2n+2){margin-right:0}}html{line-height:1.15;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}body{margin:0}header,nav,section{display:block}h1{font-size:2em;margin:.67em 0}figure,main{display:block}figure{margin:1em 40px}a{background-color:transparent;-webkit-text-decoration-skip:objects}img{border-style:none}svg:not(:root){overflow:hidden}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}html{-webkit-box-sizing:border-box;box-sizing:border-box}body{-webkit-overflow-scrolling:touch}*,::after,::before{-webkit-box-sizing:inherit;box-sizing:inherit}.site{display:-webkit-box;display:-ms-flexbox;display:flex;min-height:100vh;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column}.site__content{-webkit-box-flex:1;-ms-flex:1;flex:1}img{max-width:100%;height:auto;width:auto;vertical-align:middle}figure{margin:0}body{background-color:#fff;font-family:-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Hiragino Sans GB","Microsoft YaHei","WenQuanYi Micro Hei",sans-serif;font-size:1rem;line-height:1.5;color:#343851;-webkit-font-smoothing:antialiased;-webkit-text-size-adjust:100%}p{margin-top:0;margin-bottom:1.25rem}h1,h2{color:#313237;margin-top:0;margin-bottom:.5rem}a{color:#277cea;text-decoration:none;border-bottom:1px dashed #277cea}.blur{background:#fff;filter:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg"><filter id="filter"><feGaussianBlur stdDeviation="16" /></filter></svg>#filter');-webkit-filter:blur(1rem);filter:blur(1rem)}.container{padding:0 20px;max-width:100%;margin:0 auto}@media only screen and (min-width:36em){.container{max-width:540px;margin:0 auto}}@media only screen and (min-width:48em){.container{max-width:720px;margin:0 auto}}@media only screen and (min-width:62em){.container{max-width:960px;margin:0 auto}}@media only screen and (min-width:75em){.container{max-width:1170px;margin:0 auto}}.header{background-color:#fff;color:#343851;position:absolute;z-index:4;width:100%;top:0;left:0;will-change:transform;-webkit-transform:translateY(0);transform:translateY(0)}.header a{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border-bottom:0}.header__logo{display:-webkit-box;display:-ms-flexbox;display:flex;height:100%;overflow:hidden;padding:19px 0;margin-right:1.25rem;outline:0;border-bottom:0;color:#313237}.header__logo .header__logo--container{width:58px}.header__logo .header__logo--container .logo{fill:currentColor}.header__inner{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center;height:3.75em;-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between}.header__links{padding-bottom:.5rem;display:none;position:absolute;top:3.75em;left:0;width:100%;height:auto;background:#fff}.header__link{color:#343851;padding:.938rem 0;border-top:1px solid #ededed}.header__toggle{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;width:44px;height:100%;background-color:transparent;padding-left:1.25rem}.header__toggle span{display:block;position:relative;margin-top:4px;background-color:#343851;width:100%;height:2px;border-radius:1px}.header__toggle span:first-child{margin-top:0}@media (min-width:62em){.header__toggle{display:none;visibility:hidden}.header__links{position:static;padding:0;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;visibility:visible;width:auto;height:100%}.header__links-wrapper{display:-webkit-box;display:-ms-flexbox;display:flex;height:100%;padding:0}.header__link{position:relative;padding:.938rem 1rem;border:0;height:100%}.header__link::after{content:"";display:block;position:absolute;left:0;bottom:0;height:3px;width:100%;-webkit-transform:scaleX(0);transform:scaleX(0);background:#277cea}}.post-card{display:block;position:relative;width:100%;min-height:250px;border-radius:4px;overflow:hidden;background-color:#fff;-webkit-box-shadow:0 1px 3px rgba(0,0,0,.08);box-shadow:0 1px 3px rgba(0,0,0,.08);margin-bottom:2.25rem;border-bottom:0}@media only screen and (min-width:48em){.post-card{width:48.4375%;margin-right:3.125%}.post-card:nth-child(2n+2){margin-right:0}}@media only screen and (min-width:75em){.post-card{width:31.25%;margin-right:3.125%}.post-card:nth-child(2n+2){margin-right:3.125%}}.post-card__label{position:absolute;top:1.5rem;left:1.5rem;z-index:2}.post-card__inner{display:block;position:relative;padding:1.875rem 1.25rem .625rem;width:100%;color:#838c8d;border-bottom:0}.post-card__header{margin-bottom:.75rem}.post-card__meta{font-size:.875rem}.post-card__thumb{margin:0;background:#fff;position:relative;overflow:hidden}.post-card__thumb::after{content:"";display:block;height:0;width:100%;padding-bottom:56.25%}.post-card__thumb>*{position:absolute;top:0;left:0;width:100%;height:100%;display:block}.label{padding:0 10px;margin-bottom:1rem;display:inline-block;line-height:20px;font-size:.75rem;text-transform:uppercase;letter-spacing:1px;color:rgba(255,255,255,.8);border:2px solid rgba(255,255,255,.5);border-radius:100px}.hero{margin:3.75rem auto 0;min-height:16.25rem;width:100%;position:relative;background-color:#dde5ea;background-repeat:no-repeat;background-position:50%;background-size:cover}@media only screen and (min-width:62em){.hero{margin:0 auto;height:36em}}.hero::before{position:absolute;display:block;content:"";top:0;left:0;width:100%;height:100%;background:rgba(52,56,81,.8)}.hero__wrap{position:absolute;margin:auto;top:50%;left:50%;-webkit-transform:translate(-50%,-50%);transform:translate(-50%,-50%);text-align:center;color:rgba(255,255,255,.8);width:100%;max-width:90%;z-index:1}.hero__wrap .hero__title{font-size:1.8em;color:#fff}.blog{background-color:#f9f9f9}.post-list{padding-top:2.5em;display:-webkit-box;display:-ms-flexbox;display:flex;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-box-flex:1;-ms-flex:1 0 auto;flex:1 0 auto}@media only screen and (min-width:48em){.hero__wrap{max-width:40em}.hero__wrap .hero__title{padding:1rem 0;font-size:2.625em;line-height:3.125rem}.post-list{padding-top:5em}}</style><link rel="preload" href="/assets/css/main.css" as="style" onload="this.rel='stylesheet'"> <noscript><link rel="stylesheet" href="/assets/css/main.css"></noscript> <script type="text/javascript"> /*! loadCSS. [c]2017 Filament Group, Inc. MIT License */ (function(w){"use strict";if(!w.loadCSS){w.loadCSS=function(){}} var rp=loadCSS.relpreload={};rp.support=(function(){var ret;try{ret=w.document.createElement("link").relList.supports("preload")}catch(e){ret=!1} return function(){return ret}})();rp.bindMediaToggle=function(link){var finalMedia=link.media||"all";function enableStylesheet(){link.media=finalMedia} if(link.addEventListener){link.addEventListener("load",enableStylesheet)}else if(link.attachEvent){link.attachEvent("onload",enableStylesheet)} setTimeout(function(){link.rel="stylesheet";link.media="only x"});setTimeout(enableStylesheet,3000)};rp.poly=function(){if(rp.support()){return} var links=w.document.getElementsByTagName("link");for(var i=0;i<links.length;i++){var link=links[i];if(link.rel==="preload"&&link.getAttribute("as")==="style"&&!link.getAttribute("data-loadcss")){link.setAttribute("data-loadcss",!0);rp.bindMediaToggle(link)}}};if(!rp.support()){rp.poly();var run=w.setInterval(rp.poly,500);if(w.addEventListener){w.addEventListener("load",function(){rp.poly();w.clearInterval(run)})}else if(w.attachEvent){w.attachEvent("onload",function(){rp.poly();w.clearInterval(run)})}} if(typeof exports!=="undefined"){exports.loadCSS=loadCSS} else{w.loadCSS=loadCSS}}(typeof global!=="undefined"?global:this)) </script></head><body class="site"><header class="header" itemscope itemtype="http://schema.org/SiteNavigationElement" aria-label="Main navigation"><div class="container"><div class="header__inner"> <a class="header__logo" href="/"><div class="header__logo--container"> <?xml version="1.0" encoding="utf-8"?> <!-- Generator: Adobe Illustrator 17.1.0, SVG Export Plug-In . SVG Version: 6.00 Build 0) --> <!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"> <svg version="1.1" id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 50 50" enable-background="new 0 0 50 50" xml:space="preserve"><path d="M40.348,23.401l-15-10.909c-0.351-0.256-0.826-0.256-1.177,0l-15,10.909c-0.446,0.324-0.545,0.95-0.22,1.396 c0.325,0.447,0.949,0.544,1.397,0.221l1.974-1.436v13.718c0,0.553,0.448,1,1,1h8.075c0.552,0,1-0.447,1-1v-9.393h4.725v9.393 c0,0.553,0.448,1,1,1h8.075c0.552,0,1-0.447,1-1V23.583l1.974,1.436c0.178,0.129,0.384,0.191,0.587,0.191 c0.309,0,0.614-0.143,0.81-0.412C40.894,24.352,40.794,23.726,40.348,23.401z M35.197,36.301h-6.075v-9.393c0-0.553-0.448-1-1-1 h-6.725c-0.552,0-1,0.447-1,1v9.393h-6.075V22.128l10.438-7.591l10.438,7.591V36.301z"/> </svg></div></a><nav class="header__links"><div class="container header__links-wrapper"> <a class="header__link" href="/" itemprop="url"> <span itemprop="name">Home</span> </a> <a class="header__link" href="/about" itemprop="url"> <span itemprop="name">About</span> </a> <a class="header__link" href="/contact" itemprop="url"> <span itemprop="name">Contact</span> </a></div></nav><div class="header__toggle"> <span></span> <span></span> <span></span></div></div></div></header><div class="hero lazyload" data-bg="http://localhost:4000//assets/img/posts/kmeans_cover.jpg"><div class="hero__wrap"><div class="hero__categories"> <a class="label" href="//categories/#visualization">visualization</a> &nbsp; <a class="label" href="//categories/#clustering">clustering</a></div><h1 class="hero__title">K-Means Clustering for Image Color Segmentation</h1><p class="hero__meta"> <span> <time>02 Jan 2020</time>&nbsp;&middot; </span> <span> 8 mins read </span></p></div></div><main class="site__content"><div class="container"><article class="post-content" itemprop="articleBody"><h1 id="extracting-information-from-images-using-k-means-clustering">Extracting Information from Images Using K-Means Clustering</h1><p>You’ve probably heard the phrase “a picture is worth a thousand words.” In our digitally-advanced age, this is more accurate than ever; a lot of information can be extracted from an image. High-level computer vision systems have allowed self-driving cars to recognize whether an object is a pedestrian crossing or a static road hazard up ahead, and Instagram filters are face-detecting and interactive. These advancements stem from the most of the fundamental approaches of machine learning.</p><p>Machine learning involves the learning process machines undertake in order to understand data and provide some answers about the data. In the context of image processing, an application of machine learning could be the attempt to process an image digitally, with numbers that represent the pixels and colors as data.</p><p>Approaches that don’t provide prediction or assume a correct set of outputs but instead uncover insights from a given dataset are referred to as unsupervised. One such technique for image processing and information extraction is Kmeans clustering, a learning approach that aims to partition n data points into k groups.</p><h2 id="background-on-k-means">Background on K-Means</h2><p>The Kmeans clustering technique can be illustrated by the following rock collecting analogy. Suppose I’d like to separate a collection of rocks of various sizes and colors into 3 subgroups.</p><p><img src="https://i.imgur.com/RArtpOd.png" alt="" /></p><p>I start by randomly selecting 3 different rocks as models to represent each group.</p><p><img src="https://i.imgur.com/5AY6skk.png" alt="" /></p><p>I then group each of the remaining rocks with the 3 rock types based on size-similarity.</p><h3 id="first-iteration">First Iteration</h3><table><thead><tr><th style="text-align: center">Group 1</th><th style="text-align: center">Group 2</th><th style="text-align: center">Group 3</th></tr></thead><tbody><tr><td style="text-align: center"><img src="https://i.imgur.com/zoMMoe2.png" alt="" /></td><td style="text-align: center"><img src="https://i.imgur.com/YyzHfgL.png" alt="" /></td><td style="text-align: center"><img src="https://i.imgur.com/6U05nSB.png" alt="" /></td></tr></tbody></table><p>Once I have 3 subgroups, I find the mean rock size of each group. The rocks that best exemplify the rock size of their respective group become the new model rock. Now I can reallocate the rest of the rocks based on size-similarity to the new models, and the size mean of each group is redetermined. This process repeats until the new mean of each group does not change significantly from the previous mean, meaning that the convergence point has been reached and are rocks are organized properly.</p><p>Some number of iterations later, the groups resulting from this KMeans clustering should be more homogeneous than the original mix. Group 1 | Group 2 | Group 3 :————————-:|:————————-: | :————————-: <img src="https://i.imgur.com/9jwvfLJ.jpg" alt="" /> |<img src="https://i.imgur.com/gSdctgw.jpg" alt="" />|<img src="https://i.imgur.com/qz6MfeO.jpg" alt="" /></p><h2 id="kmeans-clustering-on-the-first-image">Kmeans clustering on the first image</h2><p>A restriction of this process is that we have only have access to digital images of rocks, not physical rock specimens themselves. So instead of size, we’ll cluster based on color.</p><p>If we consider the digital images as collections of data points that represent pixeled coordinates, we can try applying some math (K-Means) to its numbers.</p><p>Before beginning the implementation, download these packages:</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
import numpy as np
import cv2
from skimage import io
from google.colab.patches import cv2_imshow
</code></pre></div></div><h2 id="data-processing">Data Processing</h2><p>We start by reading in the link to the image we are interested in working with.</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>url = "https://i.imgur.com/RArtpOd.png" #first image
img = io.imread(url)
</code></pre></div></div><p>To see the contents of these numbers, simply print them. You should see:</p><p><img src="https://i.imgur.com/kPMrdqB.png" alt="" /></p><p>It is also important to understand the size of the image. In Python, we have converted it to a numpy data storage type. To see its dimensions, run:</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>img.shape #(500, 500, 4)
</code></pre></div></div><p>A tuple containing the number of rows, columns and layers of image is returned. You can think of each layer as a shade/filter of the image that gives it its raw appearance.</p><p>Make a copy of the image we are clustering. This is in case we make modifications and want to preserve the original data.</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>img_init = img.copy() # save a copy of initial image, will modify this image for clustering
</code></pre></div></div><p>To view the image in its raw form:</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>plt.figure(figsize=(6, 6)) # plot initial image
plt.imshow(img_init)
</code></pre></div></div><p>We use <em>matplotlib</em>’s plotting function and <em>figsize=(6,6)</em> is just the size of our output viewing window in the colab notebook.</p><p>It should appear exactly as expected.</p><p><img src="https://i.imgur.com/IltxwKj.png" alt="" /></p><p>Reshape the image above into a workable format, such as a 2-dimensional shape, like this:</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>img = img.reshape((img.shape[0] * img.shape[1],img.shape[2])) 
</code></pre></div></div><h2 id="model-fitting">Model Fitting</h2><p>Fitting the model means to apply our tool to our data in order to familiarize our model with the contents of the data.</p><p>Create an instance of the KMeans class. This basically means that we grab the <em>KMeans</em> tool from our set of <em>sklearn</em> toolbox.</p><p>Suppose that we’d like to extract 5 groups or colors from our dataset. We do this by passing in <em>n=5</em> as a parameter.</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>k = 5
clt = KMeans(n_clusters = k) # "pick out" the K-means tool from our collection of algorithms
clt.fit(img) # apply the model to our data, the image
</code></pre></div></div><h2 id="handling-the-output">Handling the Output</h2><p>The output of our model will need to be stored somehow. Create a numpy array that has the length of the number of clusters, starting at 0.</p><p>Let’s observe what the model outputs so far after fitting. Run:</p><p><img src="https://i.imgur.com/CZDhWav.png" alt="" /></p><p>The first 3 datapoints belong to group <em>4</em> and the last 3 points belong to group <em>2</em>. Somewhere in between, there should be some assortment of 0s, 1s, and 3s for the assigned group labels.</p><p>To represent the number of colors we want to observe and in what quantity they appear in the image, a histogram will be used to portray the proportions.</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>label_indx = np.arange(0,len(np.unique(clt.labels_)) + 1) 
</code></pre></div></div><p>This initializes an array of length == # clusters, setting the indices for the histogram</p><p>Each “data” point of the image array will consist of its own color class label, so we plot the frequency of each color. The more a certain color appears in an image, the more data points it will have associated with it</p><p><img src="https://i.imgur.com/spfxuak.png" alt="" /></p><p>Since the output of this are two arrays, and we only want to focus on the first one for the histogram, we use (_) to denote an empty storage, let the second array “go to nothing”</p><p>Normalize the numbers within the array to get proportions that amount to 1.</p><p><img src="https://i.imgur.com/f6vJfk4.png" alt="" /></p><p>The proportions for each class label. From above, the frequency count for some unknown color, 67942, makes up approximately 27% of all the colors.</p><p>Next, create a grid to hold our colors and their proportionate components.</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>hist_bar = np.zeros((50, 300, 3), dtype = "uint8") 
</code></pre></div></div><p>‘Np.zeros()’ initializes an array of some arbitary shape. Here, we choose a shape that spans 50 pixels in height and 300 pixels in length.</p><p>Loop over the percentage of each cluster and the color of each cluster. A loop is something that causes a command to repeat over and over for some duration, each time iterating over some variable, we iterate over 2 arrays containing the color frequencies and the cluster centers.</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>startX = 0
for (percent, color) in zip(hist,  clt.cluster_centers_): 
  endX = startX + (percent * 300) # to match grid
  cv2.rectangle(hist_bar, (int(startX), 0), (int(endX), 50),
      color.astype("uint8").tolist(), -1)
  startX = endX
</code></pre></div></div><p>Colors are identified with ‘color.astype(“uint8”)’ that converts the numbers into another color representation that tells Python that a certain number will be identified as a particular color. Remember that initially, we converted the image into its numerical representation. This is just the undoing of that first process.</p><p><code class="language-plaintext highlighter-rouge">cv2.rectangle()</code> builds the rectanglur grid, with sections that match the partitions of each color</p><h2 id="plotting-the-output">Plotting the output</h2><p>Plot both the original image and its color/quantity extraction.</p><p><img src="https://i.imgur.com/xDGKYlr.jpg" alt="" /></p><p>The first gray group has the largest proportion, followed by a brownish/red group and so on. Exact colors are not extracted, but with artistic perception and some shading involved, you could probably achieve it!</p><p>If we enlarge our K to 10, we’ll see a wider variety of colors seen in the image.</p><p><img src="https://i.imgur.com/dpGh5CL.png" alt="" /></p><p>Testing for a new image for K = 5:</p><p><img src="https://i.imgur.com/L3aNnM6.png" alt="" /></p><p>Make note that the larger K is, the more computation and time it takes to complete</p><h1 id="conclusion">Conclusion</h1><p>By following the logic of KMeans clustering, we were able to automate the assortment of colors within an image. The digital image provides information only on the colors it possesses. By considering its pixeled coordinates and color features, we can specify the number of clusters we want to observe, fit the model based on that specified number, and return the colors and their proportions.</p><p>Going forward, if the dataset included information on the rock’s size and weight in grams, perhaps you could cluster based on size, fulfilling the intial analogy provided.</p><p>What other images can you try?</p></article><div class="post-content controls__inner"><div class="controls__item prev"></div><div class="controls__item next"> <span>Next</span> <a href="/streamlit-stockviz/"> Stock Visualizer Web Applic... <span> <svg xmlns="http://www.w3.org/2000/svg" width="6" height="11"><path fill="#fillColor" d="M.353 9.282c-.37.434-.323 1.09.106 1.465a1.016 1.016 0 0 0 1.446-.107L5.75 6.125a1.05 1.05 0 0 0-.017-1.378L1.784.34A1.015 1.015 0 0 0 .336.27a1.05 1.05 0 0 0-.07 1.468l3.34 3.725L.353 9.282z"/> </svg> </span> </a></div></div></div><div class="comments"><div class="container"><div class="post-content"><div id="disqus_thread"></div><script> var disqus_config = function () { this.page.url = 'http://localhost:4000/kmeans-color/'; this.page.identifier = 'http://localhost:4000/kmeans-color/'; }; (function() { var d = document, s = d.createElement('script'); s.src = 'https://chriztopherton.disqus.com/embed.js'; s.setAttribute('data-timestamp', +new Date()); (d.head || d.body).appendChild(s); })(); </script> <noscript>Please enable JavaScript to view the comments.</noscript></div></div></div></main><footer class="footer"><div class="container"><nav class="social"> <a class="social__link" target="_blank" rel="noopener noreferrer" href="https://github.com/chriztopherton"> <svg class="social__icon" viewBox="0 0 20 20" width="20px" height="20px"><path d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg> </a></nav><span>&copy; 2021 Christopher&#39;s Blog. All rights reserved.</span></div></footer><script async src="/assets/js/bundle.js"></script> <script async> if ('serviceWorker' in navigator) { navigator.serviceWorker.register('/sw.js').then(function( registration ) { console.log('ServiceWorker registration successful with scope: ', registration.scope); }) .catch(function(error) { console.log('ServiceWorker registration failed: ', error); }); } </script></body></html>
